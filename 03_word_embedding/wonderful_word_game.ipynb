{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37c77629",
   "metadata": {},
   "source": [
    "# 유사한 단어찾기 게임\n",
    "1. 사전 학습된 모델 또는 적절한 데이터셋을 찾는다.\n",
    "2. 워드 임베딩 모델으 학습시칸다\n",
    "3. 단어유사도가 0.8 이상인  a,b를 랜덤 추출한다\n",
    "4. A,B와 대응되는 C를 추출한다\n",
    "5. D를 입력받는다 \n",
    "=> \n",
    "A:B = C:D관계에 대응하는 D를 찾는 게임을 만든다 \n",
    "ex) A:산, B:바다, C:나무, D:물\n",
    "\n",
    "**출력예시**\n",
    "\n",
    "관계 [ 수긍 : 추락 = 대사관 : ? ]\n",
    "모델이 예측한 가장 적합한 단어 : 잠입\n",
    "당신의 답변과 모델 예측 유사도 : 0.34\n",
    "아쉽네요. 더 생각해보세요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890a6515",
   "metadata": {},
   "source": [
    "**출력예시**\n",
    "\n",
    "관계 [ 수긍 : 추락 = 대사관 : ? ]\n",
    "모델이 예측한 가장 적합한 단어 : 잠입\n",
    "당신의 답변과 모델 예측 유사도 : 0.34\n",
    "아쉽네요. 더 생각해보세요\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c90ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리된 문장 개수: 192122\n",
      "전처리된 첫 번째 문장: ['때', '보고', '지금', '다시']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "data = pd.read_csv('naver_movie_ratings.txt', sep='\\t')\n",
    "document = data['document']\n",
    "\n",
    "okt = Okt()\n",
    "def preprocess(text):\n",
    "\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "\n",
    "    text = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]', '', str(text))\n",
    "\n",
    "    return okt.nouns(text)\n",
    "\n",
    "\n",
    "preprocessed_sentences = document.apply(preprocess).tolist()\n",
    "\n",
    "preprocessed_sentences = [s for s in preprocessed_sentences if s]\n",
    "\n",
    "print(f\"전처리된 문장 개수: {len(preprocessed_sentences)}\")\n",
    "print(f\"전처리된 첫 번째 문장: {preprocessed_sentences[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc307aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 벡터의 크기: (13741, 100)\n"
     ]
    }
   ],
   "source": [
    "# Word2Vec 모델 학습\n",
    "model = Word2Vec(\n",
    "    sentences = preprocessed_sentences,\n",
    "    vector_size = 100,  \n",
    "    window = 5,      \n",
    "    min_count = 5,      \n",
    "    sg = 0             \n",
    ")\n",
    "\n",
    "\n",
    "print(f\"모델 벡터의 크기: {model.wv.vectors.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9987f645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "찾은 유사 단어 쌍: 현상, 조심\n"
     ]
    }
   ],
   "source": [
    "# import random\n",
    "\n",
    "# def find_similar_words(model, similarity_threshold=0.8):\n",
    "#     all_words = list(model.wv.index_to_key)\n",
    "#     while True:\n",
    "#         a = random.choice(all_words)\n",
    "#         b = random.choice(all_words)\n",
    "#         if a == b:\n",
    "#             continue\n",
    "#         try:\n",
    "#             similarity = model.wv.similarity(a, b)\n",
    "#             if similarity > similarity_threshold:\n",
    "#                 return a, b\n",
    "#         except KeyError:\n",
    "#             continue\n",
    "\n",
    "import random\n",
    "\n",
    "def find_similar_words(model, similarity_threshold=0.8):\n",
    "    \"\"\"유사도 임계값 이상의 단어 쌍 (A, B)을 찾습니다.\"\"\"\n",
    "    all_words = list(model.wv.index_to_key)\n",
    "    \n",
    "    while True:\n",
    "        a = random.choice(all_words)\n",
    "        b = random.choice(all_words)\n",
    "        if a == b:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            similarity = model.wv.similarity(a, b)\n",
    "\n",
    "            if similarity > similarity_threshold:\n",
    "                return a, b\n",
    "        except KeyError:\n",
    "\n",
    "            continue\n",
    "\n",
    "\n",
    "word_a, word_b = find_similar_words(model, similarity_threshold=0.8)\n",
    "print(f\"찾은 유사 단어 쌍: {word_a}, {word_b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f0a523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "찾은 관계 단어: 빠삐용\n"
     ]
    }
   ],
   "source": [
    "def find_unrelated_word(model, word_a, word_b):\n",
    "    \"\"\"A, B와 관계가 없는 단어 C를 찾습니다.\"\"\"\n",
    "    all_words = list(model.wv.index_to_key)\n",
    "    \n",
    "    while True:\n",
    "        c = random.choice(all_words)\n",
    "\n",
    "        if c not in [word_a, word_b]:\n",
    "            return c\n",
    "\n",
    "\n",
    "word_c = find_unrelated_word(model, word_a, word_b)\n",
    "print(f\"찾은 관계 단어: {word_c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8530ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 데이터셋을 로드하고 모델을 학습시키는 중...\n",
      "   - 전처리 완료.\n",
      "   - Word2Vec 모델 학습 완료.\n",
      "------------------------------\n",
      "2. 유사 단어 찾기 게임 시작!\n",
      "게임을 종료하려면 '종료'를 입력하세요.\n",
      "------------------------------\n",
      "관계 [ 정자 : 돼지고기 = 토마스 : ? ]\n",
      "모델이 예측한 가장 적합한 단어 : 고요한\n",
      "당신의 답변과 모델 예측 유사도 : 0.87\n",
      "정답입니다.\n",
      "------------------------------\n",
      "관계 [ 공연장 : 저녁 = 부정 : ? ]\n",
      "모델이 예측한 가장 적합한 단어 : 누군가\n",
      "당신의 답변과 모델 예측 유사도 : 0.80\n",
      "정답입니다.\n",
      "------------------------------\n",
      "관계 [ 박재정 : 격감 = 차라 : ? ]\n",
      "모델이 예측한 가장 적합한 단어 : 칼부림\n",
      "당신의 답변과 모델 예측 유사도 : 0.55\n",
      "아쉽네요. 더 생각해보세요.\n",
      "------------------------------\n",
      "관계 [ 미미 : 만호 = 감각 : ? ]\n",
      "모델이 예측한 가장 적합한 단어 : 디테일\n",
      "당신의 답변과 모델 예측 유사도 : 0.62\n",
      "정답입니다.\n",
      "------------------------------\n",
      "관계 [ 실험영화 : 짤 = 트럭 : ? ]\n",
      "입력한 단어가 모델에 없습니다. 다시 시도해주세요.\n",
      "------------------------------\n",
      "관계 [ 코비 : 박하 = 위화 : ? ]\n",
      "모델이 예측한 가장 적합한 단어 : 정선\n",
      "당신의 답변과 모델 예측 유사도 : 0.57\n",
      "아쉽네요. 더 생각해보세요.\n",
      "------------------------------\n",
      "관계 [ 인력 : 형상 = 껄껄 : ? ]\n",
      "모델이 예측한 가장 적합한 단어 : 유민\n",
      "당신의 답변과 모델 예측 유사도 : 0.89\n",
      "정답입니다.\n",
      "------------------------------\n",
      "관계 [ 엔돌핀 : 최정원 = 윌리엄스 : ? ]\n",
      "입력한 단어가 모델에 없습니다. 다시 시도해주세요.\n",
      "------------------------------\n",
      "관계 [ 아이스에이지 : 밀러 = 큐브릭 : ? ]\n",
      "게임을 종료합니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# !pip install pandas gensim konlpy\n",
    "\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "import random\n",
    "\n",
    "\n",
    "print(\"1. 데이터셋을 로드하고 모델을 학습\")\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv('naver_movie_ratings.txt', sep='\\t')\n",
    "    document = data['document']\n",
    "except FileNotFoundError:\n",
    "    print(\"오류-파일을 찾을 수 없음.  파일 경로를 확인해야함\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "\n",
    "    text = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]', '', str(text))\n",
    "\n",
    "    return okt.nouns(text)\n",
    "\n",
    "\n",
    "preprocessed_sentences = document.apply(preprocess).tolist()\n",
    "preprocessed_sentences = [s for s in preprocessed_sentences if s]\n",
    "\n",
    "print(\"   - 전처리 완료.\")\n",
    "\n",
    "\n",
    "model = Word2Vec(\n",
    "    sentences=preprocessed_sentences,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=5,\n",
    "    sg=0,\n",
    "    workers=4\n",
    ")\n",
    "print(\"   - Word2Vec 모델 학습 완료.\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "def find_similar_words(model, similarity_threshold=0.7):\n",
    "    all_words = list(model.wv.index_to_key)\n",
    "    while True:\n",
    "        a = random.choice(all_words)\n",
    "        try:\n",
    "\n",
    "            similar_candidates = [\n",
    "                (w, sim) for w, sim in model.wv.most_similar(a, topn=30)\n",
    "                if sim > similarity_threshold\n",
    "            ]\n",
    "            if similar_candidates:\n",
    "                b, sim = random.choice(similar_candidates)\n",
    "                return a, b\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "\n",
    "def find_unrelated_word(model, word_a, word_b):\n",
    "    \"\"\"A, B와 관련 없는 단어 C를 무작위로 찾습니다.\"\"\"\n",
    "    all_words = list(model.wv.index_to_key)\n",
    "    while True:\n",
    "        c = random.choice(all_words)\n",
    "        if c not in [word_a, word_b]:\n",
    "            return c\n",
    "\n",
    "def find_analogy(model, a, b, c):\n",
    "    \"\"\"A:B = C:D 관계에서 D를 예측합니다.\"\"\"\n",
    "\n",
    "    result = model.wv.most_similar(positive=[c, b], negative=[a], topn=1)\n",
    "    if result:\n",
    "        return result[0][0], result[0][1] # (단어, 유사도)\n",
    "    return None, 0\n",
    "\n",
    "\n",
    "print(\"2. 유사 단어 찾기 게임 시작!\")\n",
    "print(\"게임을 종료하려면 '종료'를 입력하세요.\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "while True:\n",
    "    # 3단계: 유사 단어 쌍 (A, B) 추출\n",
    "    word_a, word_b = find_similar_words(model, similarity_threshold=0.7)\n",
    "    \n",
    "    # 4단계: 관계에 대응하는 단어 (C) 추출\n",
    "    word_c = find_unrelated_word(model, word_a, word_b)\n",
    "\n",
    "    # 모델이 예측한 가장 적합한 단어 (정답) 찾기\n",
    "    model_d, model_similarity = find_analogy(model, word_a, word_b, word_c)\n",
    "\n",
    "    print(f\"관계 [ {word_a} : {word_b} = {word_c} : ? ]\")\n",
    "    user_d = input(\"답변은? \")\n",
    "\n",
    "    if user_d == '종료':\n",
    "        print(\"게임을 종료합니다.\")\n",
    "        break\n",
    "    \n",
    "    try:\n",
    "        user_similarity = model.wv.similarity(user_d, model_d)\n",
    "        \n",
    "\n",
    "        print(f\"모델이 예측한 가장 적합한 단어 : {model_d}\")\n",
    "        print(f\"당신의 답변과 모델 예측 유사도 : {user_similarity:.2f}\")\n",
    "        \n",
    "        if user_similarity > 0.7: # 정답 유사도 기준\n",
    "            print(\"정답입니다.\")\n",
    "        else:\n",
    "            print(\"아쉽네요. 더 생각해보세요.\")\n",
    "        \n",
    "    except KeyError:\n",
    "        print(\"입력한 단어가 모델에 없습니다. 다시 시도해주세요.\")\n",
    "\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae065fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 데이터셋을 로드하고 모델을 학습시키는 중...\n",
      "   - 전처리 완료. 전처리된 문장 개수: 192122\n",
      "   - 전처리된 첫 번째 문장: ['때', '보고', '지금', '다시']\n",
      "   - Word2Vec 모델 학습 완료. 모델 벡터의 크기: (13741, 100)\n",
      "------------------------------\n",
      "2. 유사 단어 찾기 게임 시작!\n",
      "게임을 종료하려면 '종료'를 입력하세요.\n",
      "------------------------------\n",
      "관계 [ 강마 : 마스크 = 미녀삼총사 : ? ]\n",
      "게임을 종료합니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# !pip install pandas gensim konlpy\n",
    "\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "import random\n",
    "\n",
    "\n",
    "print(\"1. 데이터셋을 로드하고 모델을 학습시키는 중...\")\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv('naver_movie_ratings.txt', sep='\\t')\n",
    "    document = data['document']\n",
    "except FileNotFoundError:\n",
    "    print(\"오류: 'naver_movie_ratings.txt' 파일을 찾을 수 없습니다. 파일 경로를 확인해주세요.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "# 전처리 함수\n",
    "def preprocess(text):\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    text = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]', '', str(text))\n",
    "\n",
    "    return okt.nouns(text)\n",
    "\n",
    "\n",
    "preprocessed_sentences = document.apply(preprocess).tolist()\n",
    "preprocessed_sentences = [s for s in preprocessed_sentences if s]\n",
    "\n",
    "print(f\"   - 전처리 완료. 전처리된 문장 개수: {len(preprocessed_sentences)}\")\n",
    "print(f\"   - 전처리된 첫 번째 문장: {preprocessed_sentences[0]}\")\n",
    "\n",
    "\n",
    "model = Word2Vec(\n",
    "    sentences=preprocessed_sentences,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=5,\n",
    "    sg=0,\n",
    "    workers=4\n",
    ")\n",
    "print(f\"   - Word2Vec 모델 학습 완료. 모델 벡터의 크기: {model.wv.vectors.shape}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def find_similar_words(model, similarity_threshold=0.7):\n",
    "    \"\"\"Word2Vec most_similar을 이용해 더 자연스러운 단어 쌍을 찾음\"\"\"\n",
    "    all_words = list(model.wv.index_to_key)\n",
    "    while True:\n",
    "        a = random.choice(all_words)\n",
    "        try:\n",
    "\n",
    "            similar_candidates = [\n",
    "                (w, sim) for w, sim in model.wv.most_similar(a, topn=30)\n",
    "                if sim > similarity_threshold\n",
    "            ]\n",
    "            if similar_candidates:\n",
    "                b, sim = random.choice(similar_candidates)\n",
    "                return a, b\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "def find_unrelated_word(model, word_a, word_b):\n",
    "    \"\"\"A, B와 관련 없는 단어 C를 무작위로 찾습니다.\"\"\"\n",
    "    all_words = list(model.wv.index_to_key)\n",
    "    while True:\n",
    "        c = random.choice(all_words)\n",
    "        if c not in [word_a, word_b]:\n",
    "            return c\n",
    "\n",
    "def find_analogy(model, a, b, c):\n",
    "    \"\"\"A:B = C:D 관계에서 D를 예측합니다.\"\"\"\n",
    "    result = model.wv.most_similar(positive=[c, b], negative=[a], topn=1)\n",
    "    if result:\n",
    "        return result[0][0], result[0][1]  # (단어, 유사도)\n",
    "    return None, 0\n",
    "\n",
    "\n",
    "\n",
    "print(\"2. 유사 단어 찾기 게임 시작!\")\n",
    "print(\"게임을 종료하려면 '종료'를 입력하세요.\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "while True:\n",
    "    # 3단계: 유사 단어 쌍 (A, B) 추출\n",
    "    word_a, word_b = find_similar_words(model, similarity_threshold=0.7)\n",
    "\n",
    "    # 4단계: 관계에 대응하는 단어 (C) 추출\n",
    "    word_c = find_unrelated_word(model, word_a, word_b)\n",
    "\n",
    "    # 모델이 예측한 가장 적합한 단어 (정답) 찾기\n",
    "    model_d, model_similarity = find_analogy(model, word_a, word_b, word_c)\n",
    "\n",
    "    # 사용자 입력 받기\n",
    "    print(f\"관계 [ {word_a} : {word_b} = {word_c} : ? ]\")\n",
    "    user_d = input(\"당신의 답변은? \")\n",
    "\n",
    "    if user_d == '종료':\n",
    "        print(\"게임을 종료합니다.\")\n",
    "        break\n",
    "\n",
    "\n",
    "    try:\n",
    "        user_similarity = model.wv.similarity(user_d, model_d)\n",
    "\n",
    "        print(f\"모델이 예측한 가장 적합한 단어 : {model_d}\")\n",
    "        print(f\"당신의 답변과 모델 예측 유사도 : {user_similarity:.2f}\")\n",
    "\n",
    "        if user_similarity > 0.7:\n",
    "            print(\"정답입니다.\")\n",
    "        else:\n",
    "            print(\"아쉽네요. 더 생각해보세요.\")\n",
    "\n",
    "    except KeyError:\n",
    "        print(\"입력한 단어가 모델에 없습니다. 다시 시도해주세요.\")\n",
    "\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e279de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 데이터셋을 로드하고 모델을 학습시키는 중...\n",
      "    - 전처리 완료. 전처리된 문장 개수: 31986\n",
      "    - 전처리된 첫 번째 문장: ['눈엣', '가시', '몹시', '보기', '사람'] ...\n",
      "    - Word2Vec 학습 완료. 어휘 수: 8076 | 벡터 차원: 200\n",
      "    - 사용된 min_count 값: 5\n",
      "------------------------------\n",
      "2. 유사 단어(아날로지) 게임 시작!\n",
      "게임을 종료하려면 '종료'를 입력하세요.\n",
      "------------------------------\n",
      "관계 [ 실무 : 목별 = 앞서 : ? ]\n",
      "모델이 예측한 가장 적합한 단어 : 지점 (관계 일관성: 0.51)\n",
      "입력한 단어 '나중에'가 모델 어휘에 없습니다. (철자/형태를 확인해보세요)\n",
      "참고 후보: 지점(rel 0.51), 도착(rel 0.50), 수비(rel 0.42), 좌우(rel 0.41), 외야(rel 0.34)\n",
      "------------------------------\n",
      "관계 [ 구세주 : 왕후 = 공동체 : ? ]\n",
      "모델이 예측한 가장 적합한 단어 : 비판 (관계 일관성: 0.65)\n",
      "입력한 단어 '단합'가 모델 어휘에 없습니다. (철자/형태를 확인해보세요)\n",
      "참고 후보: 비판(rel 0.65), 취직(rel 0.61), 혜택(rel 0.57), 소득(rel 0.56), 무질서(rel 0.49)\n",
      "------------------------------\n",
      "관계 [ 적삼 : 웃옷 = 사이 : ? ]\n",
      "모델이 예측한 가장 적합한 단어 : 공간 (관계 일관성: 0.46)\n",
      "당신의 답변과 모델 예측 유사도 : 0.26\n",
      "아쉽네요. 다음 문제로 가볼까요?\n",
      "참고 후보: 공간(rel 0.46), 멱살(rel 0.36), 도우(rel 0.36), 깜박(rel 0.35), 관계도(rel 0.34)\n",
      "------------------------------\n",
      "관계 [ 바닷물고기 : 매실 = 출전 : ? ]\n",
      "모델이 예측한 가장 적합한 단어 : 최저 (관계 일관성: 0.39)\n",
      "당신의 답변과 모델 예측 유사도 : 0.77\n",
      "정답입니다.\n",
      "참고 후보: 최저(rel 0.39), 시즌(rel 0.34)\n",
      "------------------------------\n",
      "관계 [ 어조 : 브라질 = 다소 : ? ]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 248\u001b[39m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m관계 [ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ma\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m : ? ]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m user_d = \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m당신의 답변은? \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.strip()\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m user_d == \u001b[33m'\u001b[39m\u001b[33m종료\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    250\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m게임을 종료합니다.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\nlp312\\Lib\\site-packages\\ipykernel\\kernelbase.py:1275\u001b[39m, in \u001b[36mKernel.raw_input\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m   1273\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1274\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1275\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1276\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1277\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1278\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1279\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1280\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\nlp312\\Lib\\site-packages\\ipykernel\\kernelbase.py:1320\u001b[39m, in \u001b[36mKernel._input_request\u001b[39m\u001b[34m(self, prompt, ident, parent, password)\u001b[39m\n\u001b[32m   1317\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1318\u001b[39m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[32m   1319\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mInterrupted by user\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1320\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1321\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1322\u001b[39m     \u001b[38;5;28mself\u001b[39m.log.warning(\u001b[33m\"\u001b[39m\u001b[33mInvalid Message:\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "\n",
    "# # !pip install pandas gensim konlpy beautifulsoup4\n",
    "\n",
    "# import pandas as pd\n",
    "# from gensim.models import Word2Vec\n",
    "# import re\n",
    "# from konlpy.tag import Okt\n",
    "# import random\n",
    "# import glob\n",
    "# from bs4 import BeautifulSoup\n",
    "# import numpy as np\n",
    "# import sys\n",
    "\n",
    "# random.seed(42)\n",
    "\n",
    "\n",
    "# print(\"1. 데이터셋을 로드하고 모델을 학습시키는 중...\")\n",
    "\n",
    "\n",
    "# def parse_xml_files(file_paths):\n",
    "#     sentences = []\n",
    "#     for file_path in file_paths:\n",
    "#         try:\n",
    "#             with open(file_path, 'r', encoding='utf-8') as f:\n",
    "#                 xml_data = f.read()\n",
    "#         except Exception as e:\n",
    "#             print(f\"[경고] {file_path} 읽기 실패: {e}\")\n",
    "#             continue\n",
    "\n",
    "#         soup = BeautifulSoup(xml_data, 'xml')\n",
    "#         lexical_entries = soup.find_all('LexicalEntry')\n",
    "        \n",
    "#         for entry in lexical_entries:\n",
    "#             word_tag = entry.find('Lemma')\n",
    "#             if not word_tag:\n",
    "#                 continue\n",
    "#             feat_tag = word_tag.find('feat', {'att': 'writtenForm'})\n",
    "#             if not feat_tag or not feat_tag.has_attr('val'):\n",
    "#                 continue\n",
    "#             word = feat_tag['val']\n",
    "\n",
    "#             definitions = []\n",
    "#             for s in entry.find_all('Sense'):\n",
    "#                 feat = s.find('feat', {'att': 'definition'})\n",
    "#                 if feat and feat.has_attr('val'):\n",
    "#                     definitions.append(feat['val'])\n",
    "\n",
    "#             if definitions:\n",
    "#                 sentence = word + ' ' + ' '.join(definitions)\n",
    "#                 sentences.append(sentence)\n",
    "#     return sentences\n",
    "\n",
    "\n",
    "# try:\n",
    "#     xml_files = glob.glob(\"*.xml\")\n",
    "#     if not xml_files:\n",
    "#         raise FileNotFoundError\n",
    "#     raw_sentences = parse_xml_files(xml_files)\n",
    "# except FileNotFoundError:\n",
    "#     print(\"오류: 현재 디렉터리에서 XML 파일을 찾을 수 없습니다.\")\n",
    "#     sys.exit(0)\n",
    "\n",
    "# okt = Okt()\n",
    "\n",
    "# def preprocess(text):\n",
    "#     if pd.isna(text) or not isinstance(text, str):\n",
    "#         return []\n",
    "\n",
    "#     text = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]', ' ', text)\n",
    "\n",
    "#     nouns = [n for n in okt.nouns(text) if len(n) >= 2]\n",
    "#     return nouns\n",
    "\n",
    "# preprocessed_sentences = [preprocess(s) for s in raw_sentences]\n",
    "# preprocessed_sentences = [s for s in preprocessed_sentences if s]\n",
    "\n",
    "# if not preprocessed_sentences:\n",
    "#     print(\"전처리된 문장이 없습니다. XML 데이터를 확인하세요.\")\n",
    "#     sys.exit(0)\n",
    "\n",
    "# print(f\"    - 전처리 완료. 전처리된 문장 개수: {len(preprocessed_sentences)}\")\n",
    "# print(f\"    - 전처리된 첫 번째 문장: {preprocessed_sentences[0][:15]} ...\")\n",
    "\n",
    "# min_count = 5 if len(preprocessed_sentences) > 500 else 2\n",
    "# model = Word2Vec(\n",
    "#     sentences=preprocessed_sentences,\n",
    "#     vector_size=200,\n",
    "#     window=5,\n",
    "#     min_count=min_count,\n",
    "#     sg=0,\n",
    "#     workers=4\n",
    "# )\n",
    "# wv = model.wv\n",
    "# print(f\"    - Word2Vec 학습 완료. 어휘 수: {len(wv.index_to_key)} | 벡터 차원: {wv.vectors.shape[1]}\")\n",
    "# print(f\"    - 사용된 min_count 값: {min_count}\")\n",
    "# print(\"-\" * 30)\n",
    "\n",
    "# def is_valid_token(token):\n",
    "#     if token is None:\n",
    "#         return False\n",
    "#     if token not in wv:\n",
    "#         return False\n",
    "\n",
    "#     if any(ch.isdigit() for ch in token):\n",
    "#         return False\n",
    "#     if len(token) >= 10:\n",
    "#         return False\n",
    "\n",
    "#     try:\n",
    "#         cnt = wv.get_vecattr(token, \"count\")\n",
    "#         if cnt < max(min_count, 3):\n",
    "#             return False\n",
    "#     except Exception:\n",
    "#         pass\n",
    "#     return True\n",
    "\n",
    "# def cosine(u, v):\n",
    "#     un = np.linalg.norm(u); vn = np.linalg.norm(v)\n",
    "#     if un == 0 or vn == 0:\n",
    "#         return 0.0\n",
    "#     return float(np.dot(u, v) / (un * vn))\n",
    "\n",
    "\n",
    "# def pick_similar_pair(sim_min=0.45, sim_max=0.92, max_trials=200):\n",
    "#     \"\"\"\n",
    "#     A를 뽑고, A와 '적당히' 유사한 B를 고른다.\n",
    "#     너무 가까운 동의어/중복은 피하고, 너무 먼 관계도 피함.\n",
    "#     \"\"\"\n",
    "#     vocab = [w for w in wv.index_to_key if is_valid_token(w)]\n",
    "#     for _ in range(max_trials):\n",
    "#         a = random.choice(vocab)\n",
    "#         try:\n",
    "#             cands = [(w, s) for w, s in wv.most_similar(a, topn=40)\n",
    "#                      if is_valid_token(w) and sim_min <= s <= sim_max and w != a]\n",
    "#             if not cands:\n",
    "#                 continue\n",
    "#             b = random.choice(cands)[0]\n",
    "#             return a, b\n",
    "#         except KeyError:\n",
    "#             continue\n",
    "#     return None, None\n",
    "\n",
    "# def pick_c_close_to_a(a, b, sim_a_min=0.35, sim_a_max=0.85, sim_b_max=0.55, max_trials=200):\n",
    "#     \"\"\"\n",
    "#     C는 A와 '같은 범주'로 보이도록 A와 어느 정도 비슷하게 고른다.\n",
    "#     단, B와는 너무 가깝지 않게 하여 삼항이 망가지지 않도록 함.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         neighbors = [w for w, s in wv.most_similar(a, topn=60)]\n",
    "#     except KeyError:\n",
    "#         return None\n",
    "#     random.shuffle(neighbors)\n",
    "#     for c in neighbors:\n",
    "#         if c in (a, b) or not is_valid_token(c):\n",
    "#             continue\n",
    "#         try:\n",
    "#             sim_ac = wv.similarity(a, c)\n",
    "#             sim_bc = wv.similarity(b, c)\n",
    "#         except KeyError:\n",
    "#             continue\n",
    "#         if sim_a_min <= sim_ac <= sim_a_max and sim_bc <= sim_b_max:\n",
    "#             return c\n",
    "\n",
    "#     vocab = [w for w in wv.index_to_key if is_valid_token(w)]\n",
    "#     random.shuffle(vocab)\n",
    "#     for c in vocab[:200]:\n",
    "#         if c in (a, b):\n",
    "#             continue\n",
    "#         try:\n",
    "#             sim_ac = wv.similarity(a, c)\n",
    "#             sim_bc = wv.similarity(b, c)\n",
    "#         except KeyError:\n",
    "#             continue\n",
    "#         if sim_a_min <= sim_ac <= sim_a_max and sim_bc <= sim_b_max:\n",
    "#             return c\n",
    "#     return None\n",
    "\n",
    "# def solve_analogy(a, b, c, topn=15):\n",
    "#     \"\"\"\n",
    "#     3CosMul로 D 후보를 구하고, 관계 일관성 점수로 필터링.\n",
    "#     관계 일관성 = cos( (b-a), (d-c) )\n",
    "#     \"\"\"\n",
    "#     if not all(t in wv for t in [a, b, c]):\n",
    "#         return None, 0.0, []\n",
    "#     try:\n",
    "#         # 3CosMul 사용\n",
    "#         cand_list = wv.most_similar_cosmul(positive=[b, c], negative=[a], topn=topn+5)\n",
    "#     except Exception:\n",
    "#         # gensim 버전에 따라 cosmul 미지원 시 fallback\n",
    "#         cand_list = wv.most_similar(positive=[b, c], negative=[a], topn=topn+5)\n",
    "\n",
    "#     av, bv, cv = wv[a], wv[b], wv[c]\n",
    "#     rel_vec = bv - av\n",
    "#     filtered = []\n",
    "#     for d, base_score in cand_list:\n",
    "#         if d in (a, b, c) or not is_valid_token(d):\n",
    "#             continue\n",
    "#         score_rel = cosine(rel_vec, wv[d] - cv)\n",
    "\n",
    "#         if score_rel >= 0.30:\n",
    "#             filtered.append((d, base_score, score_rel))\n",
    "#         if len(filtered) >= topn:\n",
    "#             break\n",
    "\n",
    "#     if not filtered:\n",
    "#         return None, 0.0, []\n",
    "\n",
    "\n",
    "#     filtered.sort(key=lambda x: (x[2], x[1]), reverse=True)\n",
    "#     d, base_score, rel_score = filtered[0]\n",
    "#     return d, rel_score, filtered[:5]  # 상위 5개 후보 반환\n",
    "\n",
    "\n",
    "# print(\"2. 유사 단어(아날로지) 게임 시작!\")\n",
    "# print(\"게임을 종료하려면 '종료'를 입력하세요.\")\n",
    "# print(\"-\" * 30)\n",
    "\n",
    "# while True:\n",
    "#     try:\n",
    "#         # 문제 생성 (여러 번 시도 -> 그럴듯한 삼항으로 )\n",
    "#         ok = False\n",
    "#         for _ in range(30):\n",
    "#             a, b = pick_similar_pair()\n",
    "#             if not a or not b:\n",
    "#                 continue\n",
    "#             c = pick_c_close_to_a(a, b)\n",
    "#             if not c:\n",
    "#                 continue\n",
    "#             d, rel_score, top5 = solve_analogy(a, b, c, topn=10)\n",
    "#             if d and rel_score >= 0.32:\n",
    "#                 ok = True\n",
    "#                 break\n",
    "#         if not ok:\n",
    "#             print(\"적절한 문제를 만들기 어려워 다음 문제로 넘어갑니다.\")\n",
    "#             print(\"-\" * 30)\n",
    "#             continue\n",
    "\n",
    "#         print(f\"관계 [ {a} : {b} = {c} : ? ]\")\n",
    "#         user_d = input(\"당신의 답변은? \").strip()\n",
    "#         if user_d == '종료':\n",
    "#             print(\"게임을 종료합니다.\")\n",
    "#             break\n",
    "\n",
    "#         # 모델 예측 및 피드백\n",
    "#         print(f\"모델이 예측한 가장 적합한 단어 : {d} (관계 일관성: {rel_score:.2f})\")\n",
    "#         try:\n",
    "#             user_sim = wv.similarity(user_d, d)\n",
    "#             print(f\"당신의 답변과 모델 예측 유사도 : {user_sim:.2f}\")\n",
    "#             if user_d == d or user_sim >= 0.70:\n",
    "#                 print(\"정답입니다.\")\n",
    "#             elif user_sim >= 0.50:\n",
    "#                 print(\"아주 근접\")\n",
    "#             else:\n",
    "#                 print(\"아쉽네요. 다음 문제 \")\n",
    "#         except KeyError:\n",
    "#             print(f\"입력한 단어 '{user_d}'가 모델 어휘에 없습니다. (철자/형태를 확인해보세요)\")\n",
    "\n",
    "\n",
    "#     except (IndexError, AttributeError, KeyError) as e:\n",
    "#         print(f\"[경고] 예외 발생: {e}. 다음 문제로 넘어갑니다.\")\n",
    "#         print(\"-\" * 30)\n",
    "#         continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0878e70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 데이터셋을 로드하고 모델을 학습시키는 중...\n",
      "    - 전처리 완료. 전처리된 문장 개수: 32127\n",
      "    - 전처리된 첫 번째 문장: ['눈엣', '가시', '몹시', '보기', '사람']\n",
      "    - Word2Vec 모델 학습 완료. 모델 벡터의 크기: (8655, 100)\n",
      "------------------------------\n",
      "2. 유사 단어 찾기 게임 시작!\n",
      "게임을 종료하려면 '종료'를 입력하세요.\n",
      "------------------------------\n",
      "관계 [ 옛날 : 신선 = 화이트보드 : ? ]\n",
      "모델이 예측한 가장 적합한 단어 : 나사\n",
      "당신의 답변과 모델 예측 유사도 : 0.81\n",
      "정답입니다.\n",
      "------------------------------\n",
      "관계 [ 개선 : 첨단 = 컴퍼스 : ? ]\n",
      "모델이 예측한 가장 적합한 단어 : 번갈아\n",
      "당신의 답변과 모델 예측 유사도 : 0.24\n",
      "아쉽네요. 더 생각해보세요.\n",
      "------------------------------\n",
      "관계 [ 타당성 : 마태복음 = 명단 : ? ]\n",
      "모델이 예측한 가장 적합한 단어 : 구성원\n",
      "당신의 답변과 모델 예측 유사도 : 0.30\n",
      "아쉽네요. 더 생각해보세요.\n",
      "------------------------------\n",
      "관계 [ 스크린 : 상표 = 양 : ? ]\n",
      "모델이 예측한 가장 적합한 단어 : 염소\n",
      "당신의 답변과 모델 예측 유사도 : 0.70\n",
      "정답입니다.\n",
      "------------------------------\n",
      "관계 [ 이유나 : 부림 = 부분 : ? ]\n",
      "모델이 예측한 가장 적합한 단어 : 아래쪽\n",
      "당신의 답변과 모델 예측 유사도 : 0.46\n",
      "아쉽네요. 더 생각해보세요.\n",
      "------------------------------\n",
      "관계 [ 협력 : 조언 = 인용 : ? ]\n",
      "모델이 예측한 가장 적합한 단어 : 부호\n",
      "당신의 답변과 모델 예측 유사도 : 0.25\n",
      "아쉽네요. 더 생각해보세요.\n",
      "------------------------------\n",
      "관계 [ 시간대 : 일정 = 리다 : ? ]\n",
      "게임을 종료합니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# !pip install pandas gensim konlpy beautifulsoup4\n",
    "\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "import random\n",
    "import glob\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "print(\"1. 데이터셋을 로드하고 모델을 학습시키는 중...\")\n",
    "\n",
    "\n",
    "def parse_xml_files(file_paths):\n",
    "    sentences = []\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            xml_data = f.read()\n",
    "        \n",
    "        soup = BeautifulSoup(xml_data, 'xml')\n",
    "        lexical_entries = soup.find_all('LexicalEntry')\n",
    "        \n",
    "        for entry in lexical_entries:\n",
    "\n",
    "            word_tag = entry.find('Lemma')\n",
    "            if word_tag:\n",
    "                word = word_tag.find('feat', {'att': 'writtenForm'})['val']\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "\n",
    "            definitions = [\n",
    "                s.find('feat', {'att': 'definition'})['val'] \n",
    "                for s in entry.find_all('Sense') \n",
    "                if s.find('feat', {'att': 'definition'})\n",
    "            ]\n",
    "            \n",
    "            if definitions:\n",
    "                sentence = word + ' ' + ' '.join(definitions)\n",
    "                sentences.append(sentence)\n",
    "                \n",
    "    return sentences\n",
    "\n",
    "\n",
    "try:\n",
    "    xml_files = glob.glob(\"*.xml\")\n",
    "    if not xml_files:\n",
    "        raise FileNotFoundError\n",
    "    \n",
    "\n",
    "    raw_sentences = parse_xml_files(xml_files)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"오류: 현재 디렉터리에서 XML 파일을 찾을 수 없습니다.\")\n",
    "    exit()\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    if pd.isna(text) or not isinstance(text, str):\n",
    "        return []\n",
    "    text = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]', '', text)\n",
    "    return okt.nouns(text)\n",
    "\n",
    "\n",
    "preprocessed_sentences = [preprocess(s) for s in raw_sentences]\n",
    "preprocessed_sentences = [s for s in preprocessed_sentences if s]\n",
    "\n",
    "print(f\"    - 전처리 완료. 전처리된 문장 개수: {len(preprocessed_sentences)}\")\n",
    "print(f\"    - 전처리된 첫 번째 문장: {preprocessed_sentences[0]}\")\n",
    "\n",
    "model = Word2Vec(\n",
    "    sentences=preprocessed_sentences,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=5,\n",
    "    sg=0,\n",
    "    workers=4\n",
    ")\n",
    "print(f\"    - Word2Vec 모델 학습 완료. 모델 벡터의 크기: {model.wv.vectors.shape}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "def find_similar_words(model, similarity_threshold=0.5):\n",
    "    \"\"\"Word2Vec most_similar을 이용해 더 자연스러운 단어 쌍을 찾음\"\"\"\n",
    "    all_words = list(model.wv.index_to_key)\n",
    "    while True:\n",
    "        a = random.choice(all_words)\n",
    "        try:\n",
    "            similar_candidates = [\n",
    "                (w, sim) for w, sim in model.wv.most_similar(a, topn=30)\n",
    "                if sim > similarity_threshold\n",
    "            ]\n",
    "            if similar_candidates:\n",
    "                b, sim = random.choice(similar_candidates)\n",
    "                return a, b\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "def find_unrelated_word(model, word_a, word_b):\n",
    "    \"\"\"A, B와 관련 없는 단어 C를 무작위로 찾습니다. A, B와는 유의미한 거리를 가집니다.\"\"\"\n",
    "    all_words = list(model.wv.index_to_key)\n",
    "    while True:\n",
    "        c = random.choice(all_words)\n",
    "\n",
    "        if c not in [word_a, word_b]:\n",
    "            try:\n",
    "\n",
    "                if model.wv.similarity(word_a, c) < 0.3 and model.wv.similarity(word_b, c) < 0.3:\n",
    "                    return c\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "def find_analogy(model, a, b, c):\n",
    "    \"\"\"A:B = C:D 관계에서 D를 예측합니다.\"\"\"\n",
    "    if not all(word in model.wv for word in [a, b, c]):\n",
    "        return None, 0\n",
    "    \n",
    "    result = model.wv.most_similar(positive=[c, b], negative=[a], topn=1)\n",
    "    if result:\n",
    "        return result[0][0], result[0][1]\n",
    "    return None, 0\n",
    "\n",
    "\n",
    "print(\"2. 유사 단어 찾기 게임 시작!\")\n",
    "print(\"게임을 종료하려면 '종료'를 입력하세요.\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        word_a, word_b = find_similar_words(model)\n",
    "        word_c = find_unrelated_word(model, word_a, word_b)\n",
    "        \n",
    "        if not word_c:\n",
    "            print(\"적절한 유추 단어를 찾을 수 없습니다. 다음 문제로 넘어갑니다.\")\n",
    "            print(\"-\" * 30)\n",
    "            continue\n",
    "\n",
    "        model_d, model_similarity = find_analogy(model, word_a, word_b, word_c)\n",
    "\n",
    "        if not model_d:\n",
    "            print(\"적절한 유추 단어를 찾을 수 없습니다. 다음 문제로 넘어갑니다.\")\n",
    "            print(\"-\" * 30)\n",
    "            continue\n",
    "            \n",
    "        print(f\"관계 [ {word_a} : {word_b} = {word_c} : ? ]\")\n",
    "        user_d = input(\"당신의 답변은? \")\n",
    "\n",
    "        if user_d == '종료':\n",
    "            print(\"게임을 종료합니다.\")\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            user_similarity = model.wv.similarity(user_d, model_d)\n",
    "\n",
    "            print(f\"모델이 예측한 가장 적합한 단어 : {model_d}\")\n",
    "            print(f\"당신의 답변과 모델 예측 유사도 : {user_similarity:.2f}\")\n",
    "\n",
    "            if user_similarity > 0.7:\n",
    "                print(\"정답입니다.\")\n",
    "            else:\n",
    "                print(\"아쉽네요. 더 생각해보세요.\")\n",
    "\n",
    "        except KeyError:\n",
    "            print(f\"입력한 단어 '{user_d}'가 모델에 없습니다. 다시 시도해주세요.\")\n",
    "\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "    except (IndexError, AttributeError) as e:\n",
    "        print(f\"오류 발생: {e}. 게임을 다시 시작합니다.\")\n",
    "        print(\"-\" * 30)\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
